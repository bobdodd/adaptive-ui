Design for Accessible Handheld Devices

R. J. Dodd
School of Computing
University of Teesside
Tees Valley TS1 3BA, UK
r.dodd@tees.ac.uk
Dr. E. Pearson
Dr. S.J. Green


Abstract—The accessibility of mobile devices, such as mobile phones, is a unique problem domain. They present with a small form factor, constraining display size, and making serious demands on user mobility and cognition. Existing assistive technology tackles these problems through a combination of bespoke solutions and text-to-speech augmentation of the "standard" user interface, often leading to a bulking out of the device, or forcing visual metaphors upon blind users. Particularly with the expansion of value-added, downloadable, services in mobile telephony, we are fast approaching a crunch-point for user interface design. On the one hand, the new services require ever more sophisticated user interaction, and on the other, disability legislation and regulation covering e-commerce makes no distinction between browsing the web on a PC, and browsing the web on a mobile phone. To try and square the circle, this research revisits the processes by which user interfaces are designed, constructing a model of user interface development that maximizes the capabilities of each device, matching them to the physical capabilities of individual users, and selecting a set of interaction metaphors appropriate to the content, to the device, and to the user.
Keywords-accessibility; capability model; design space; self-adaptation 
DESIGNING HANDHELD DEVICES
The design of handheld devices such as mobile phones, certainly in the experience of this author, starts typically with a feature list, and an operational context that is focused on a narrow profile of targeted users. From this, use-cases are created, metaphors selected, and modalities defined and implemented. The use-case approach flows into a task-based view of the user interface: start a call, edit the phone book, or send a text message; such an approach is taken by the Avanti Project [1]. In each instance, as the use-cases further sub-divide, so the task structure of the interface design divides, with each point in this task hierarchy explicitly considered in terms of the appropriate, optimum, modality and design space. The result is a hard-coded, optimized user interface with a limited choice of modality and design space given to the end-user as personal preference settings.  Devices with greater computing power may offer a wider range of options to the user, but the designer predefines the range. Any assistive technology to enhance accessibility beyond the target user-base must then work within the limits of these pre-selected, pre-constructed, modalities and design spaces; it is no surprise that assistive technology for mobile devices has limited capability. 
In order to better support assistive technology, it is necessary to reconsider the meaning of accessibility in the context of handheld devices together with the requirements that this imposes on user interface development. In turn, these accessibility requirements will lead to a revised development process for the design of handheld devices.
WHAT MAKES A HANDHELD DEVICE ACCESSIBLE?
There is no agreed definition of accessibility for handheld devices, but one intuitive answer may be, “A device is accessible if it is usable by a broad range of users, either directly, or by the addition of appropriate assistive technology whilst retaining the character of the original device”; it is this final caveat that scopes the problem domain for handheld devices, and is characterized by a small form factor and mobility.  Assistive technology that bulks out size, or requires a device to be physically clamped to a surface, may produce an accessible device, but it is no longer a handheld device.  According to this argument, accessibility solutions for handheld devices are most likely to be found within the existing interaction mediums of any particular device, maximizing the potential of each medium to, in turn, maximize the range of supported users.
The problem with this intuitive definition of accessibility is one of measurability. In what circumstances is any particular device to be considered accessible? Which actual users comprise a “broad range of users”?  In short, how do we know if we have succeeded in creating an accessible device? This is no philosophical question: the scope of accessibility rights legislation around the world continues to strengthen and expand, with the Australian Disability Discrimination Act [2], the UK Disability Discrimination Act [3] and the US Americans With Disabilities Act [4] as prime examples. What such legislation tends to have in common is a requirement to provide access to goods and services, and with the arrival of e-tailing on mobile devices, particularly modern mobile phones, consideration of accessibility must move beyond provision of basic telephony services, to consider value-added services and the physical and cognitive demands that these place upon the users of the device. 
SCOPING ACCESSIBILITY
Taking a lead from the legislative aspects of accessibility, a broader definition of accessibility is, “Goods and services are accessible if the provider of the goods or services offers a means by which a broad range of users may enter into a dialogue with the provider to gain access to them at any given place and time.”  This definition does two things; it focuses on the dialogue between user and provider rather than on a specific device, and it scopes context of that dialogue. A shift to a dialogue perspective allows us to say that specific mobile devices may support access to goods and services for a limited set of users, and that accessibility is obtained through the provision of a range of devices. This should be no surprise; existing “accessibility” solutions to mobile telephony already make the assumption. For example, mobile operator Vodafone offers blind and low vision users a solution based on specific Nokia mobile phones with text-to-speech software [5], and also a different three-button phone for mobility-impaired users [6].  
The goods and services view of accessibility challenges the very notion of an accessible handheld device and the common idioms we use to describe them. If a device only provides a means for some users to hold a dialogue with a provider, then it is not meaningful to describe the device as “accessible”, nor can one describe one device as more accessible than another; it either works for a particular user, or it doesn’t. Some devices may support a broader range of users under given conditions, but that is not, in itself, a measure of accessibility.
Yet, breadth of user base for a device is important: one unique solution for every combination and every level of user disability is simply impractical when one considers the number of unique physical impairments associated with sight, hearing, mobility, and cognition. The broader the range of users supported by a particular phone, the simpler it becomes for an operator to provide access to their services, assuming that a smaller range of devices is, generally, easier and cheaper to support.
So, the key measurable aspect of handheld devices related to accessibility is breadth of user base, and more importantly in knowing which users are contained within it; if a telecoms provider is to ensure access to goods and services through providing a range of alternative devices, they must know which device supports what users most effectively. Whilst this may seem a truism, the breadth and complexity of human physiology makes such measurement, and more importantly, such estimation, very difficult. Jacko’s investigation of sight [7] for example, includes consideration of color perception, stereo perception, field of vision, and ability to focus. These impairments, which also vary in degree, are likely to impact on the design of a user interface in different ways. Hearing, mobility, and cognition are similarly expressible, and this leads to a multiplying of potential disability profiles as many disabled users have more than one disability e.g. a person with Multiple Sclerosis may have double vision, no sense of touch, and limited mobility. Whilst few disabled users will experience quite that range of impairment, multiple impairments are a common feature of ageing.
USER CAPABILITY MODEL
To measure the user base of a specific device, it is first necessary to understand who all the potential users of any device might be (otherwise how do you know who to test for?).  Such a list of users and their capabilities would be informed by their capabilities in terms of sight, hearing, mobility, and cognition and these, in turn, require accurate, and relatively detailed models of each of these capabilities. Each model represents the capability set of that “sense”. 
Capability sets based grouped on sight, hearing, mobility and cognition are not entirely independent of each other. One example, again from Multiple Sclerosis (MS), is the ability to focus. Often people with MS will have double or blurred vision, but they also have mobility problems, and these may manifest as uncontrollable shaking of the hands; if you cannot hold a device steady, then your ability to focus on a point on the device, say the screen, becomes impaired, compounding and exacerbating any other visual impairment.
Iterating through a model of user capability identifies the (rather large, but finite) set of potential users, and is, for any particular model of human physiology, constant. As such, it provides the basis for independent, quantitative identification of user breadth across a range of devices/interfaces being used to providing a good or service. Two caveats to this statement are required. First, quantization: such a list can only be finite in the digital world, not in the analogue e.g. if blurred vision is a graded capability of sight, then the grading must be sampled into finite steps, and the quality of the resulting model will depend on the quantization error of the sampling. Second, realism: in iterating through the capability models purely combinatorially would produce some very odd “people”. Whilst it may be theoretically possible to be both blind and have tunnel vision, it is meaningless in terms of real users; the constraints of human physiology must be applied during construction of the models, and during iteration.
Having the set of all potential users leads to more questions. What is the measure of success for an individual user to access a device? Is such a measure a Boolean pass/fail indication, or are there degrees of success? Under which operating conditions is the measure true?
DESIGN SPACES
Interaction between user and device requires appropriate selection of communications media, together with appropriate modes of interaction within the chosen media. Expanding upon Nesbitt’s multi-sensory design space [8] such interactions occur within the visual, sonic, haptic, and cognitive design spaces, with each design space having it’s own unique character and operating constraints. Successful interaction requires effective mapping between user capabilities and physical properties of the selected design spaces. A user with good vision may expect to utilize primarily the visual design space. A user with more restricted vision may require some interaction to be mapped to the sonic design space, or possibly both, for example a user with dyslexia may wish to both see a text message, and to hear it.
For successful interaction, the design of a handheld device will therefore depend, at least partly, upon choosing the most appropriate design spaces for a given user capability model. Assuming the user’s capability set remains constant, this dependency must also be constant. Therefore, for each potential user we have identified, we may now statically identify the most ideal design spaces. That is not to say that another selection will not be accessible, but it may not be as usable, and this suggests that there are at least degrees of usability, if not accessibility.
METAPHOR SETS
Placing user interaction within the best available design space is, in itself, not a guarantee of accessibility. Each of the three design spaces, visual, sonic, and haptic, contain a broad range of physical properties capable of use as communications media, but not all will be appropriate to specific user capabilities. Whilst the visual design space may be considered the most effective design space for a user with relatively good sight, an impairment of color perception for example, constrains the physical properties of the visual design space available for communication. 
Since the physical properties of a design space are intimately related to the significance applied to the values of those properties within the user interface, they are also intimately bound to the interaction metaphors we choose to embed those signifiers within, for example relative physical size to express importance in the visual design space. This allows for a static mapping between the physical property of the design space and potential information signifiers, and between the signifiers and supported interaction metaphors.
Further, since we know what are the most effective design spaces for a particular user, and we know which signifiers are available in each design spaces for that user, and we know which metaphors use which signifiers, we also know which subset of the available supported metaphors best match a particular user (and which of the available metaphors will match that user, even if not optimal) for any given device. Assuming the device supports a rich metaphor set, effective selection of appropriate interaction metaphors becomes dependent upon operational context and user preference, and more importantly on the character of the content being communicated.
ABSTRACT USER INTERFACES
Separating the meaning of what we wish to express from how we choose to express that content is not new, and examples abound within user interface design including, for example, the XForms initiative of the World Wide Web Consortium [9] and discussed in detail by Trewin et al [10]. The need to do so however, becomes more urgent when the underlying design spaces, and hence the available metaphor set, that support its expression are effectively unstable; this is the case with current mobile telephony, where device capability varies enormously from device to device. In addition, the need to vary the selected design space, and the selected properties within each design space in order to satisfy a broad range of user capabilities, and the case for abstract user interfaces for handheld devices in particular, becomes compelling. 
From the perspective of measuring the breadth of user-base, we need to know which, of the available interaction metaphors that are supported by the device, are appropriate to the content to be communicated. Since actual content may not be known until runtime e.g. RSS news feeds [11], the focus moves to the supporting ontology for the content. So, for example, what metaphors can express relative position in a graph, or importance in a news feed? Mapping “what” to “how on this particular device”, answers such questions, with the answer being a subset of the available supported metaphors. The intersection of this subset with the set of usable metaphors for the given user defines whether the content is accessible or not; if the intersection is the empty set, then the content is not accessible. This leads to the observation that there are degrees of accessibility measurable in terms of information loss in the rendered user interface, and degrees of richness in supporting content navigation.
The focus upon ontologies raises concerns of its own. Which content ontologies should a device support? With a traditional mobile phone, the designer knows this answer in advance because the features of basic mobile telephony are well known and well understood. But downloadable, value added services such as online banking, travel directions, and games are problematic. Since the answer cannot be known in advance, there is only one practical solution and that is to limit measures of user-base to “out of the box” core behavior, and to measure the user-base independently for each value added service. So we would consider the breadth of the user-base for basic telephony, and separately for web browsing, banking, games etc. This is quite reasonable as our model of accessibility is based on the supply of individual goods and services, not on the general accessibility of a specific device.
OPERATIONAL CONTEXT
So far the appropriateness of signifiers and metaphors for communicating content has been approached in terms of a specific operational context but handheld devices, by their nature, tend to be used in a range of different environments.  Mobile phones, for example, operate in a range of hostile environments including bright sunshine, noisy streets, and in swaying, shaking trains. Consequently, it is also necessary to consider appropriateness in terms of the impact of the environment upon the handheld device. 
 In the same way as user capability was expressed in terms of design space, it also possible to construct a model of device capability, considering the impact of lighting, noise, and stability, on each design space. This leads to another mapping, this time between the physical aspects of the design space for differing environmental conditions, giving the usable physical properties for each given environmental condition; knowing the usable physical properties allows filtering of potential signifiers, and hence potential metaphors, identified as available for a specific user, but now on a context-sensitive basis. For a given set of supported metaphors, this set of usable metaphors is static.
There are, of course, factors other than environmental constraints that form part of an operational context. These include cultural references to social etiquette, the significance of particular colors, and established custom and practice in navigating user interfaces. With mobile devices there are also health and safety issues that can limit the use of particular design spaces (or parts of them) in particular contexts, for example the banning of radio transmissions on aircraft. Each of these additional contextual constraints can be considered a filter on the available interaction metaphors. Some, such as aircraft safety are easily identifiable, those related to cultural custom and practice much less so, but they all, to greater or lesser extent, impact upon accessibility. This leads to the observation that the granularity of any such filtering applied is likely to directly affect the outcome of measures of user-base breadth.
CHOOSING A USER-BASE 
If measuring the accessibility of handheld devices is wrapped up in the precise identification of the supported user-base, then this must also be true when designing them.  After all, how can a product be designed without knowing who the prospective users will be? Yet in practice this appears to be what happens; it is a challenge to find existing products that did select their user base from all of the potential disabled users discussed here, assuming that they identified any at all.
Returning to the established customs and practices of mobile phone development, the first clear and obvious impact of accessibility is upon the choice of target users.  Since we are measuring accessibility in terms of the provision of goods and services, selection of target users is unlikely to, and almost certainly will not, require supporting the entire set of potential users on a single device. So which, of all the potential users, should the device support? For commercial phones, the answer is almost certainly, “whatever the service provider requires”, and this is dependent upon the provider’s target market and legal requirements such as accessibility of goods and services. In supplying phones, manufacturers are in competition, and one element, to support legal accessibility requirements, will increasingly be breadth of user-base. In such an environment there is a commercial advantage in demonstrably maximizing the breadth of user-base; “demonstrably”, because it may be necessary to convince courts and lawyers that best efforts have been made to provide access to goods and services.
MAXIMIZING THE USER-BASE
To maximize the potential user-base of a specific design, it is necessary to consider how the user interface of the device is to be delivered. Handheld devices are physically constrained in size, and to some extent, computing power. The solution chosen for the device is therefore always likely to be a compromise between a heavily optimized specific interface, and an entirely customizable one. Further, because of the additional value added services provided through such devices, it is not possible in advance to know the complete set of interface metaphors to support. Together, these design constraints suggest we must leverage the maximum value out of the design spaces and signifiers that are supported, and provide an open, extensible interface. Such an extensible interface would require dynamic late binding between an abstract model of user interaction and its concrete realization. So, to maximize the user-base requires a particular model of interface development: abstract user interfaces. In terms of existing software development methods for embedded systems, the most promising candidate for such an approach may be Executable UML [12], which models systems based on a semantic decomposition of ontologies. This gives the possibility of one set of UML class diagrams for the abstract model (a form of Nylander’s Interaction Acts [13]), and another set for potential realizations. With this method, mapping between the abstract and concrete becomes a tabular activity, giving a clear means of adapting a user interface to the needs of a particular user. Tabular mapping also aids openness: metaphor sets and user capability sets not considered by the manufacturers, can easily be added by third-party assistive technology at no cost to the manufacturer, again widening the potential user-base and again demonstrating best-efforts at accessibility.
Executable UML may provide the means of extensibility, but it is the measure of user-base breadth that offers the greatest potential to maximize the “out-of-the-box” delivered user-base.   Starting from the primary target user-base, the design spaces available for the given device, and the preferred metaphor set (and hence physical design space properties) to support those users, it is possible to reverse-engineer the calculation of user-base breadth.
The mapping between user and usable design space immediately filters the set of potential users to those for whom the device may be in some way usable, and hence are worth considering supporting for this particular device. 
Comparing the supported metaphor set directly against the mapping of user capability to metaphor, and through this to the mapping of content to metaphor, allows us to identify which users can fully, or partly, access the device.  Where users can partly access the device i.e. where some content has no available metaphor, it is then possible to do a cost-benefit analysis to decide what additional metaphors to support these particular user categories is worthwhile.
Filtering the set of physical properties for each design space according to those initially chosen for the design, also allows us to select those users who can, to some extent, communicate using these properties; by considering the properties in the light of operational context, it is possible to identify additional potential users who simply require additional metaphors to access content. Again, a cost-benefit analysis would identify which, if any of these users should be added to the device user-base. As an aside, this is also a useful measure of how well the target users are supported.
REVISITING THE DEVELOPMENT PROCESS
Maximizing the user-base requires a change to the customs and practices of user interface development. These changes affect the whole development lifecycle. The need to correctly select the user-base requires a detailed modeling of the initial target users, their capabilities, and the metaphor set which will support them. Once this is complete, a second evaluation is required to identify the additional user capability sets considered worthwhile to support in the device; only then do we know the true scale of the development task in terms of supported users and required interaction metaphors.
Development is therefore iterative: it still starts with a feature list, and an operational context that is focused on a narrow profile of target users, it still constructs use-cases, and selects an initial metaphor set, but then the development branches. The secondary identification of users additional metaphors then proceeds in parallel with the identification of, and implementation of modalities, to support the initial set of user metaphors. So, ignoring staffing issues, extending the user base does not significantly affect the development timescale. Only additional metaphor work identified by the secondary users would do so.
Also affecting the development process is the need for an extensible solution to configuring the interface for each user capability set, and for such a system to be open to late binding, possibly including third party assistive technology. Many solutions to this are possible, but the most likely is a formal separation between an abstract model of the user interface including a navigation model, and the rendering of the concrete interface. Such semantic decomposition of concerns is again found in Executable UML’s domain charts, and these are supported within Executable UML by a specific and unique development process.
CONCLUSION
Accessibility, in the context of handheld devices, is not directly measurable; rather it is at the level of provision of goods and services to users of the device, that accessibility is measurable. Measurement of accessibility then becomes a question of coverage: taken together, does the offered range of devices provide a means for all users, disabled and non-disabled to access the goods and services? In other words, do the selected devices cover the required user-base?
Measurement of a handheld device’s user-base requires a comprehensive and finite list of users to evaluate the device against; such a list may be construction of models of the multi-sensory design space, namely sight, hearing, mobility, and cognition. By also considering the physical properties of the device in terms of sight, hearing, and mobility, it is possible to identify the most appropriate properties upon which to base user interaction. By further mapping those properties to the supported interaction metaphors of the device, it is possible to identify the most appropriate metaphors to use in interactions between user and device. With a final mapping between the ontology of the communicated content within the interface and appropriate metaphors for such content, it then becomes possible to identify whether any item of content is accessible to a particular user capability set.
Measurement of user-base is not only important from a validation perspective, it also performs a role in developing the device itself. Starting from a selected target user base, design space, and metaphor set, it is possible to use the mapping tables within the measuring process to identify additional users that may be able to access the device, either directly, or through a limited amount of additional development work. This is important from a practical viewpoint: the broader the range of user supported by a device, the less device types need to be supported by service providers, simplifying support and potentially reducing costs. 
Constructing a user interface to maximize the available user-base has implications for the development process by which handheld devices are designed. The open-ended adaptability required, suggests that modeling the interface as an abstract user interface within the Executable UML development method would have significant benefits.
Having an explicitly traceable model of accessibility also has the added advantages of guiding users to appropriate devices, and of being able to demonstratively show that, to the manufacturer’s best endeavors, accessibility in terms of breadth of user-base has been considered.
REFERENCES

Savidis A et al, “Designing user-adapted interfaces: the unified design method for transformable interactions”, Proceedings of the conference on Designing interactive systems: processes, practices, and techniques, 1997
Australian Government,, “Disability Discrimination Act 1992”,  HYPERLINK "http://www.hreoc.gov.au/disability_rights/standards/www_3/www_3.html" http://www.hreoc.gov.au/disability_rights/standards/www_3/www_3.html, accessed 3 August 2006.
UK Government, “Disability Discrimination Act 1995”, online http://www.opsi.gov.uk/acts/acts1995/1995050.htm, accessed 3 August 2006.
US Governement, “Americans With Disabilities Act 1990”, online  HYPERLINK "http://www.usdoj.gov/crt/ada/adahom1.htm" http://www.usdoj.gov/crt/ada/adahom1.htm, accessed 3 August 2006.
Voadfone plc, “Speaking Phones”,    HYPERLINK "http://access.vodafonebusiness.co.uk/speaking_phones.html" http://access.vodafonebusiness.co.uk/speaking_phones.html, accessed 3 August 2006.
Vodafone plc,  “Corporate Social Responsibility Report,  HYPERLINK "http://www.vodafone.com/assets/files/en/CSR_Report_2003-04_VF-DE_20050802.pdf" http://www.vodafone.com/assets/files/en/CSR_Report_2003-04_VF-DE_20050802.pdf, accessed 3 August 2006.
Jacko J et al, “Visual profiles: a critical component of universal access”, Proceedings of the SIGHCI conference on Human factors in computing systems: the CHI is the limit, 1999
Nesbitt K.V., “Modeling the Multi-Sensory Design Space”, In Australian symposium on Information visualization, - Volume 9 (CRPITS’01), Australian Computer Society, 2001.
W3C XForms specification version 1.0, 2006.  HYPERLINK "http://www.w3.org/TR/2006/REC-xforms-20060314/" http://www.w3.org/TR/2006/REC-xforms-20060314/.
Trewin S et al, “Abstract User Interface Representations: How Well do they Support Universal Access?”, ACM SIGCAPH Computers and the Physically Handicapped, Proceedings of the 2003 conference on Universal usability, CUU ’03, 2003
RSS Board, “Really Simple Synidcation”,  HYPERLINK "http://www.rssboard.org" http://www.rssboard.org, accessed 3 August 2006.
Mellor S, “Make Models Be Assets”, Communications of the ACM Volume 45, 11:76-87 (November 2002), 2002
Nylander S et al, “Ubiquitous service access through adapted user interfaces on multiple devices”, Personal and Ubiquitous Computing (2005) 9:123-133, 2005.




