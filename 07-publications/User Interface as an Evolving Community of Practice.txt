	User Interface as an Evolving Community of Practice

Quotations
“Being alive as human beings means that we are constantly engaged in the pursuit of enterprises of all kinds, from ensuring our physical survival to seeking the most lofty pleasures. As we define these enterprises and engage in their pursuit together, we interact with each other and with the world and we tune our relations with each other and with the world accordingly. In other words we learn. Over time, this collective learning results in practices that reflect both the pursuit of our enterprises and the attendant social relations. These practices are thus the property of a kind of community created over time by the sustained pursuit of a shared enterprise. It makes sense, therefore to call these kinds of communities.”
communities of practice. (Wenger 1998)

“A meme can be defined as an information pattern, held in an individual's memory or in an outside artifact (e.g. book, record or tool), which is likely to be communicated or copied to another individual's memory.”

Journal of Memetics  HYPERLINK "http://www.jom-emit.org/" http://www.jom-emit.org/ (accessed 21 Sept 2005)

Overview
Following on from Etienne Wenger’s presentation at ALT-C, I can see parallels between his human communities of practice and the roles extant in the expression of content in a User Interface. I’ve not read much work on CoP, so these notes are based solely on what I remember from the presentation and the odd bits I’ve read. I also have to add that I’m more interested in the concept of cooperating entities than in other aspects of CoP.
Further, so far I have considered my work to be about self-adapting user interfaces, but I begin to wonder if I don’t mean self-learning user interfaces. I can see two ways in which UIs can self-learn: through the feedback and selection choices of individual users, and through the replication and sharing of user capability profile sets between users. The first aspect expands on the classic self-adapting user interface where the standard skein is modified and/or replaced at user request. The second aspect comes from the introduction of portable user profiles (profile = preferences + tailored capability set). In terms of memetic evolution, the profile acts as the information pattern, the social behaviour of users acts as the replicator, and variation is provided by self-adaptation to specific users. 
Taking CoP and memetic evolution together gives a useful (and I suspect, unique) model of user interfaces. Semantic decomposition of the user interface into role-playing entities allows us to examine their interaction as actors in a shared endevour, namely providing content and collating feedback between device and user. The manner of that interaction (competition, power structures, decision making processes etc.) allows us to say something about why a user interface may be, or may become, inaccessible, and allows us to do so without resorting to discussion of hardware, software, ergonomics, or Internet accessibility standards. The introduction of memetic evolution through the use of portable user profiles builds on this understanding, allowing us to expand our communities of practice from abstract entities in the UI, to the disjoint sets of self-selecting users that form user communities. In particular, the disjoint sets that form around particular goals in using the UI (remembering that the same person may well be in multiple sets) gives a basis for describing how capability sets may appear and evolve over time. It also allows us to ask the question: can a purely static “accessible” user interface ever be considered truly accessible? That is to say, can any system that cannot learn from its users and adapt to changing requirements be considered accessible? And in a wider context if the adaptation cannot easily promulgate within communities of practice, again can the user interface be considered accessible?
In terms of where this fits within my research, the answer seems to be this it fits rather neatly. In fact I’d go as far as to say that this puts in words what my diagrams have been saying graphically. Semantic decomposition is the basis of my Executable UML Domain Chart in any case, and whilst my subject matter hierarchy is not an exact fit, it does tend to be a neat 1:M relationship in most cases. In those where it doesn’t, I suspect my models are wrong. So I see this abstract model of UI and Accessibility as forming the cornerstone of my thesis, with the software that I design and build being by way of evaluation of the concept, and the testing of the software against a selected user base a way of validating the semantic partitioning.
Entities
Wenger’s model seemed to be firmly based on human interaction, but since such interactions are themselves based on roles played by individuals (the same individual may be designer of one learning object, a practitioner using another, and a student on the end yet another) then the idea should be adaptable to any activity based on the roles played by collaborating entities. Applying this to a UI, we get a set of entities something like:

User capability context
User preference
Content provider
Content manager
Content presenter
Custom & Practice (convention)
Cultural context (convention)
Device capability context
Operational context
User Capability Context
The User Capability Context represents the (current) capabilities of the (current) user in terms of sight, hearing, cognition, and mobility in terms of usable design spaces and presentation and input metaphors. This context specifies which possible design spaces are available to the user, and which metaphors are relevant to them. Note: possible design spaces, the available design spaces are identified by the Device Context.
User Preference
User Preference represents active choices made by the user in selection of design space and metaphor set. Such choices may express the personal bias of the user learned outside of the scope of this specific User Interface, or be the result of feedback from the user to previously presented/suggested design spaces and metaphor sets.
Content Provider
The Content Provider is the sole representative of all function and meaning within the User Interface. For an operating system, this includes the concept of programs, file systems, and asynchronous communication with other computers. For a web browser, it represents the meaning and function of the individual pages and the meaning of the collected pages (the website) e.g. the news in an RSS news feed.
Content Manager
The Content Manager organises all function and meaning within the User Interface to optimise it for a specific user. This is not organisation of presentation or navigation, but organisation of ideas, ensuring that the ideas are composed appropriately for each user. The Content Manager’s scope therefore includes adaptation of content for user cognition/learning capabilities.
Content Presenter
The Content Presenter expresses all function and meaning as organised by the Content Manager in a form appropriate to the specific user, under instruction from User Preference, and guidance from the User Capability Context and the Device Context. Note this is expression of, not organisation of, content. An example is a file manager application; the Content Provider expresses the file system as a set of node and vertex entities; the Content Manager groups related entities together for presentation and navigation (e.g. all the files belonging to a single folder); the Content Presenter expresses a group of related entities as a rectangular grid with each grid intersection represented by a hyperlinked icon (assuming you want to re-create “My Documents” in M$ Windows).
Custom and Practice (Convention)
Custom and Practice is the guardian of all conventions typically applied to User Interface design. For example, Custom and Practice prefers visual metaphor over sonic metaphor, it also prefers rectangular 2D grids for laying out content to asymmetric shapes and 3D surfaces. As a textual example Custom and Practice prefers textual hyperlinks to be underlined and for heading text to be a larger font size than the associated body text. Put more abstractly, Custom and Practice prefers the most commonly extant metaphor sets and design spaces used in contemporary User Interface design over other, more novel, forms of User Interface. As such it forms a ‘damping’ factor in when adapting the UI for a specific user, encouraging a common presentation language, and hence engendering a sense of community and identity between all users of the device regardless of their Capability Context.
Cultural Context (Convention)
Cultural Context is the guardian of all conventions that express the acceptable metaphor sets and design spaces used by the device. Cultural Context can be global within the User Interface (e.g. the meaning of colour; western culture sees red for danger, Chinese culture sees red as lucky) or it can be Use-Case specific (e.g. use of personal stereo headphones is considered rude when in the company of others). These Use-Case specific contexts are of particular importance with mobile devices, which by their nature, tend to be used in public/shared spaces, and are therefore particularly sensitive to prevailing social etiquettes. Consequently, as with Custom and Practice, Cultural Context forms a  ‘damping’ factor when adapting the UI for a specific user, embedding user interaction within the wider social conventions of the user’s environment. This in turn helps engender a sense of common identity between users of the device and the wider community regardless of their Capability Context.
Device Capability Context
The Device Capability Context represents the (current) interaction capabilities of the device in terms of the properties of the available design spaces. It is defined in terms of current capabilities as mobile devices may alter their capability set over time e.g. memory cards and data/applications on them may be added and removed at any time; if part of the presentation software is on the card, then the capability of the device may change. 
Operational Context
The interaction between users and hand-held mobile devices is strongly influenced by location e.g. the stability of the device varies depending on the stability of the user holding it; if your hands, for any reason, shake whilst using the device (e.g. physical impairment, or caused by using the device whilst in a moving vehicle) user capability to view a screen or to select precise locations on a touch-pad may become impaired. The Operational Context represents the measure of usability of each available design space and interaction metaphor for particular operating conditions/locations.
UI Communities and Accessibility
If a User Interface can be described as a Community of Practice, then I’d define an inaccessible user interface as a dysfunctional community. The community may be dysfunctional for three possible reasons: competition between actors, inappropriate power structure within the community, an inappropriate decision making process.
Competition
There is an inherent competition for presentation capacity in resource-limited environments. Thinking particularly of hand-held mobile devices, we have small, relatively low-resolution, displays together with primitive audio and haptic capabilities, all supported by software platforms that are inflexible in their modes of operation. With such limited design spaces, and limited metaphor sets (heavily constrained by the software platform), it is easy for competition to occur. An example would be a mobile phone; the UI must support at least 4 contemporaneous features: battery level indication, voice calls, (incoming) text/multimedia messages, user-selected activity (e.g. a Java game). All four features need access to the end user, and they must therefore negotiate for access. When that negotiation becomes competition, the available presentation spaces and metaphor sets become constrained for at least some of the features, leading to a possible reduction in accessibility (e.g. if voice calls hog the audio channels, other earcons needed for low vision users may be blocked or unacceptably delayed).
Power structures
In management there is more than one possible way to organise a team, and depending upon the nature of the work, the timescales, and the personalities of the individual team members, some organisation structures work better than others. With a UI, User preference must inevitably be king, as the UI exists to serve the “external” user and their preferences. However, preference is informed and constrained by context, content and the capabilities of the presenter. Should this hierarchy be distorted, the UI community becomes dysfunctional and presentation of content will be skewed, possibly impacting on accessibility. A typical example is a web page that use fixed font sizes and fixed colour selections; even when the user provides a style-sheet, the Content Presenter thinks it ‘knows better’.
Decision-making
Effective decision-making depends on high-quality inputs, coupled with appropriate processes for verification, validation, and evaluation of those inputs, plus evaluation of the effectiveness of the outcomes. In terms of UI presentation this means starting with precise formal models of context and capability. It also means having traceability in the UI presentation process, and in particular in the decision tree that selects design space and metaphor, so that user feedback can inform future selection decisions. That user feedback should inform the decision tree implies a closed loop control system and all that entails.
Such decision-making becomes dysfunctional when the models of context and capability are missing or are at an inappropriate granularity e.g. if all ‘blind’ users can’t see, or all deaf’ users can’t hear. It is also dysfunctional when a faulty selection cannot be amended i.e. the control system becomes ‘open-loop’.
User Communities and Accessibility
Memetic Evolution
Essentially, memetics is about the promulgation and evolution of ideas. It derives from the work of Richard Dawkins work on genetics (The Selfish Gene, xxxx) abstracting the evolution processes implicit in DNA, and asserting that if Darwinian evolution can be modelled as program executing on a machine, then other machines may exist in other contexts that also capable of executing the same program. In the case of Memetics it is argued that the basic process of evolution: memory retention, copyability, and some limited variability in the copying process, is evident in the way ideas are transmitted between people, and evident in the way such ideas appear and evolve over time.
User Profile Evolution
I would argue that the same Darwinian process of evolution on which memetics is based, is evident in my model of user profiles. Taking each element of the evolution process in turn:

Memory Retention  User profiles are persistent entities. The inherent capabilities of the user remain constant unless there is a change in the users physical condition or environment independent of any specific user interface with which the user interacts. In principle, profiles may be retained using both analogue and digital technologies. Whatever the technology, the profile may be persistent well beyond the time when the users condition or environment changes. Profiles are not necessarily unique to a user (assuming a large enough sample set of users) and are susceptible to classification. Profiles are therefore retained at two levels, one generatable on-the-fly from the user’s condition and environment, and one in technological form that may, or may not, be based on the generated user capabilities and environment (the profile may be estimated based on a classification process). So we definitely have memory retention. 
Copyability  Both digital and analogue storage is capable of duplication to varying degrees of accuracy, and in principle they can be easily copied and shared. That copying process, regardless of how and when it happens, provides the necessary copyability. The engine the drives this copying is most likely to be the user, who selects what changes in the digital user profile are to be retained, and chooses with whom to share that profile. It is, of course, also possible for a user interface to automatically collate metrics of user behaviour and despatch it automatically elsewhere outside of the user’s control. 
Variability in Copying Process  One of the nice things about modern storage media is the ease of accurate duplication, and this means that variability is not guaranteed by the copying process. In the case of user profiles, variability occurs only before a work product is copied as part of the User Interface’s Community of Practice. To be more precise, it is the result changes invoked by the User Feedback entity. Such feedback is either a result of direct feedback from the user, or inferred feedback as a result of observed user behaviour. Users can (and do) make arbitrary decisions, and artificial intelligence is often a contradiction in terms, so such changes can be assumed to have a combination of intelligent selection and random choice in their makeup. So, we do have variability in the copying process, but unlike DNA (and possibly memes, depending on who you read) the variability is in the profile itself as it changes between copies, not in the copying process itself.




Shared User Profiles

Section 5.2 shows that the required mechanism for evolution exists within user profiling. How well it works will depend on what the user does with their profile, and here we come back to Wenger’s Communities of Practice. 

Does the user share their profile with others? Perhaps they share just part of it? Perhaps they just tell people about what their settings are? Perhaps they tell no one? The answer lies I would suggest, in how the user perceives that profile in relation to their own identity. If we consider identity to be expressed through the peer groups the user chooses to identify with, then potentially each peer group may receive differing amounts of information about the user’s settings. 

Applying Wenger’s concept of learning communities based on a shared enterprise, at least some of these peer groups have the potential for communication either through a central organisation, or through informal peer-to-peer communication. 

Out of all the possible learning communities there is the potential for some communities to be based on capability (often defined in terms incapability). This is perhaps more true of some geographical areas than other, particularly the US which has a “National Associations” for a remarkably wide range of disabilities. Examples in the UK include the RNIB, the RNID, and the MS Society. Such self-selecting peer groups have a natural tendency to focus of accessibility and user profiles, and to compare and contrast pooled experience. It is fair to assume that if well-known user interfaces were to be driven by portable user profiles, settings and profiles would be discussed and swapped frequently, providing an effective copying channel for evolution of appropriate profiles for that peer group.
Sharing User Profiles

Evolution is usually taken to mean a general drift in direction of the evolving entity, and by that definition, stasis in a kind of random chaos is not evolution. So, for the sharing of profiles to work, there must be some form of selection occurring that provides the required direction, and I would suggest this comes from the CoP associated with the particular peer group that is sharing the profiles (one assumes that blind users are likely to amend, delete, or ignore profiles optimised for sighted users). As the users in the CoP experiment with, and learn the limits of the user profiling mechanism provided to them, they will share and pool that experience so that poor selections quickly get weeded out and user profiles appropriate for identifiable subsets of the peer group emerge.

For a profile to evolve effectively then, it must be both easy to share, and be a near-accurate copy of the original. I would argue that a user interface that allowed user profiles to be loaded, retained, and shared without recourse to the user’s memory is likely to achieve these requirements more than one relying a user’s capability to record, share, and set up profiles themselves. In fact, depending upon user capability, it may be impossible to rely on the user’s capabilities to perform the copying process with any degree of reliability, if at all.

So, if we believe that a user interface must be tailored to a users capabilities and preferences for it to be accessible, and that that is achieved through user profiling, and that user profiling is an evolutionary process, then user interfaces that optimize user profiling to improve the evolutionary process will be more accessible than those that do not.
Definitions of Accessibility

One of the problems I keep hitting (especially in this document) when talking about how accessible a user interface may be is the difference between what leads to accessibility and what is actually accessible to specific users. Until now, and in the last draft of my registration document, I have used about universally accessible devices, but of course, by simple analysis of ergonomic issues, there’s no such thing (well, according to me anyway). As an alternative I plan to use the following definitions in my work:

Intrinsically Accessible
Functionally Accessible

Intrinsically Accessible
A user interface is intrinsically accessible if the underlying abstract design is wholly inclusive, and the built-in process of tailoring to specific users is wholly evolutionary in nature. That is to say (i) the underlying design of the interface makes no assumptions about the capabilities of the user, and so in this sense is truly universally accessible, and (ii) the mechanism and rules to tailor the interface is not fixed in the design but change over time as a result of user experience. There are many factors that make a user interface intrinsically accessible, and not all are yet known, and hence “intrinsically accessible” is may be used only in a comparative sense, you cannot say any particular user interface is intrinsically accessible, only that it is more, or less, intrinsically accessible than another.
Functionally Accessible
A user interface is functionally accessible if it is usable for specific user preference and capability sets (i.e. profiles). It is not possible to talk about a functionally accessible interface without reference to the supported user profiles that it supports. Since, by definition, all users have a user profile, all user interfaces are functionally accessible for specific users (and sometimes classifications of users) there is no such thing as a functionally inaccessible user interface. Further, since there are an arbitrary number of possible user profiles, it is impossible to use the term “functionally accessible” to compare one user interface with another. Whilst one user interface may cover a broader range of profiles than another, it is still only functionally accessible to those users who fit the supported profiles; breadth of coverage is not a measure of accessibility. In this sense, breadth of coverage is a measure usability, not accessibility.
Examples

The user interface of the Apple Macintosh operating system OSX is intrinsically more accessible than Microsoft windows because the user interface is wholly “pluggable” i.e. it can be wholly replaced when tailoring the user interface to a specific user profile. That it would be a huge task does not make it less intrinsically accessible than any other interface, it just makes it very hard work. 
Scalable Vector Graphics (SVG) are intrinsically more accessible than Macromedia Flash because SVG better supports cascading style sheets (currently Flash supports style sheets for text elements only) allowing the user interface to better adapt to a user’s preferences and capabilities. Functionally, in terns of features, they are quite similar; it is the capacity to adapt that makes one more intrinsically accessible than the other. 
The wireless switch on the Portland project is intrinsically more accessible than the standard jellybean switch, because (at least) part of the user’s profile is embedded within the switch, allowing any user interface supporting it, to interrogate the switch and to adapt to the user’s preferences and capabilities. The Portland switch may be considered less intrinsically accessible than an on-line XML-based user profiling system in some cases, since the form of profile retention enables easier copying, promoting better evolution of the profile. “Intrinsically accessible” is always a relative term and must be taken in context.

 Applicability to my Own Research
Summary of existing research

My five-step approach is currently:

Separation of UI and application
Separation of ‘what’ from ‘how’ in UI
Expansion of available design spaces
Expansion of available metaphor sets
User capability profiling

To achieve this, I apply semantic decomposition to create a domain chart. This creates a client-server model of requirements (and consequently of behaviour) that in turn fixes the decision-making process for presentation selection. A user-profiling domain is supported by a capability domain, which in turn is supported by domains representing vision, hearing, cognition and mobility. UI presentation is split between an abstract UI domain and a number of ‘pluggable universe’ domains that may render all or part of the abstract model. Similarly a device profiling domain is supported by screen, sound and tactile domains. Synchronization occurs between the abstract UI and each universe, and between pluggable universes. Content for the UI is provided by a hierarchy of Application domains, each representing either platform functionality or executable applications running on the platform. 
Mapping of CoP Roles to my research
User capability context
Capability context is represented by the hierarchy of domains below User Profiling, namely: Capability, Sight, Hearing, Cognition, Mobility.
User preference
User preference is represented within the Profiling domain which decomposes preference into session, metaphor and design space preferences and maps these preferences to particular user capabilities.
Content provider
The content provider is represented by entities within the hierarchy of application domains. Such content is described in terms of a relational model and encapsulated behaviour, so a word processor is means of modifying a document within the constraints of the document’s meta-model, and an operating system is a means of navigating and supporting a complex user-selection model based on a two-part model of activity and content. 
Content manager
The content manager is represented in part by the Abstract User Interface domain which defines a logical partitioning of content together with an associated navigational structure..
Content presenter
The abstract view held by the Content Manager is further refined by the concept of pluggable universes, which render behaviour and presentation according to a decision tree defined by context, capability, and preference. Each pluggable universe is a Content Presenter. Content Presenters must collaborate to share metaphor sets and design spaces.
Custom & Practice (i.e. convention)
Custom and Practice is expressed by the default selections for particular user profiles and capability sets. For example, it is convention (currently) for screen output to use windowing metaphors unless specific user capabilities preclude this choice. It is also a convention to present as much content visually as possible, with audio and haptics used only as complementary design spaces.
Cultural context
Cultural context is expressed through the selection of default metaphor sets e.g. the use of colour, grammar (commas for decimal point, << for quotes etc.) based on user profiling. 

Device Capability Context
Device capability context is expressed through a hierarchy of domains below Device Profile: Screen, Audio, Tactile. This allows for a precise definition of device constraints.
Operational Context
Associated with the Device Capability Context is a model of environmental constraints e.g. device stability, lighting, attention-level constraints (e.g. you may need low attention devices in hazardous environments where user concentration must be elsewhere.
Conclusion/Next Steps
On balance, I’d say the CoP/memetic model can be made quite compelling as a way to explain why user interfaces are, or can become, inaccessible. I like the fact that the argument is abstract and largely ‘solution-free’, and is therefore not an argument about software modelling techniques of user interface standards. I also like the idea that the same process of Communities of Practice can be applied at micro-level within the UI and at macro-level within user communities; that I can apply the same analytical approach to both cases gives me a “warm feeling” about its validity. That it maps so neatly onto my existing work also gives me confidence in the model. The memetic model of profile evolution also helps to set accessible user interfaces within a broader context and helps define some “missing parameters” of how we measure accessibility. It also gives some distinction between accessibility and usability, which is useful in its own right.

The areas where the argument is weakest is in the description of the abstract entities within the CoP. If it is going to work, I should able to describe the character of all of the entities quite profusely. Effectively giving them pseudo-personalities; at the moment the descriptions are a bit unbalanced in their scope. Does this mean that the subject partitioning between the entities is wrong? I don’t think so. I suspect that a decent Executable UML model will sharpen up the entity definitions, it certainly did the trick when I tried to populate my original domain chart. Actually some sleep and reflection may also help, this work has been done largely on the bus to Tsinghua Uni at 6am (the return bus is too busy to work), which may also explain why the text doesn’t always flow that well.

As for where next, I’d like to read much more about CoP, to see how much of Wenger et al’s ideas can be carried over to my model, particularly how much of the ‘learning community’ side of his work can be ported. I also need to revisit my domain chart to see if I’ve missed anything in my mapping and to consider how memetic evolution fits within it (CoP fits neatly, but I’ve never really considered the impact of user profiling in this sesnse). 






