Translative User Interfaces as Assistive Technology for Hand-held Devices

Any user interface, whether it is for a PC application, a website, or a mobile phone, is constructed upon the presumption of particular user, device, and environmental profiles.  The broader the range of each presumption in that profile is, the more accessible the interface is generally considered to be.

There are a number of different, and complementary design strategies geared at broadening such profiles. These categorize principally into two broad areas: selective, and translative. Examples of selection are, provision of alternate content such as ALT tags for image content on a web page, and written transcripts of audio streams. Examples of translation are, provision of screen-reading technology (which can utilize the provided alternate content), and cascading style sheets for web pages that allow the same content to be rendered in different ways for different users. The key difference between the approaches is organization of content. The selective approach provides alternate, or supplementary content within a fixed narrative. The translative approach manipulates the narrative itself, tailoring and prioritizing the order of presentation of content to the user. This tailoring can be seen easiest with screen-reading technology, where the order in which content is presented is manipulated to ease navigation of content, and to handle the reduction in available information bandwidth caused by the translation from visual to audio output.

Hand-held devices pose particular challenges when attempting to broaden profiles. Compared to traditional PCs and laptops, the device profile has in intrinsically narrow capability (smaller screens, limited audio processing etc.) and environmental constraints multiply (the devices are used in non-optimal lighting condition, and require more of a user’s capabilities in terms of mobility, especially motor skills). This research concentrates on translative approaches that are optimised to this specific environment.

Translative approaches are grammar, and meaning, driven.  Firstly, they must be able to read and interpret a description of the information to be conveyed between user and program, and vice versa. Secondly they must understand which physical design spaces (visual, sonic, and haptic) are most appropriate to the given user. Thirdly they must understand what metaphors can best express the required information within the identified design spaces, which are also within the capabilities of the user to perceive and understand. Finally they must (re)construct an appropriate narrative with the user. Typically, with a modern user interface, that constructed narrative will be a non-linear collection of individual dialogues.

The success of a translative approach is dependent on the quality of the, typically rule-based, decisions that it is capable of making, and they in turn depend on the quality of profile information provided; the finer the granularity of the profile information, the finer the granularity of decision making becomes. If one takes hearing as an example, an interface may be able to avoid audio cues for a user who is known to be hard of hearing. If, more specifically, it is known that the user has problems with stereo perception, then the interface can avoid the use of stereo cues, but still utilise some audio features. When dealing with hand-held devices, which have limited design spaces and capabilities, such distinctions can make a significant difference in the quality of user experience. To this end, this research constructs a detailed model of user capability which considers vision, hearing, mobility, cognition, and to a lesser extent, learning. The more detail a user chooses (and from an ethical perspective, it must be their choice) to give the interface, the more sophisticated that decision-making process becomes.

Such a decision-based system as used within this research, are heavily dependent on configuration/initialization files, some of which are specific to the application, some of which are (potentially) portable and provided by the user.  An existing example of an application specific file is a web page, which attempt to express what is to be presented with suggestions on how that is to be achieved.  An existing example of a (potentially) user-supplied file is a cascading style sheet that the user may give a web browser to adjust font sizes and colour selections. What is important to note is that both examples rely on international standards for their file formats to allow inter-operability across computing platforms. This approach becomes even more important when one considers the breadth, and variation in capability, of hand-held device platforms.

This research is not specifically about web pages, although it does rely upon the underlying concept of hypermedia for a view of user interaction, and upon XML (the standard web mark-up language) for configuration/profile file formats.  Part of the work within the project is ensuring that the structure of these files is, as far as practicable, consistent with established custom and practice particularly in the expression of user profiles. The profiles are inevitably rather more complex than some established user profiles, and are focussed on a semantic view of capability, and one of our challenges is in managing the mappings between our user profiles and other user profiles related to the subject domain of the application. In particular, since this research takes place within a department focussed on the accessibility of learning technologies, there is a particular focus on the relationship to a user’s personal learning environment, and inter-operability with it.
